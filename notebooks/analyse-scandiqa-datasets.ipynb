{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075dd561-27c7-4a75-8a3f-408f84cd2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf8705-e783-4911-8fe6-911cf823fe50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load datasetstrain_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46feff42-8a50-4abc-9af8-31ccf1d876b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = load_dataset('alexandrainst/scandiqa', 'da', use_auth_token=True, download_mode=\"force_redownload\")\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb4c44-7b28-4486-95f7-d3275001da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = load_dataset('alexandrainst/scandiqa', 'sv', use_auth_token=True, download_mode=\"force_redownload\")\n",
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77ab5d-f835-4624-a02c-e7e67e5f1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = load_dataset('alexandrainst/scandiqa', 'no', use_auth_token=True, download_mode=\"force_redownload\")\n",
    "no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e8626-ee0f-43c0-9466-9411b7d574a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd9afc-0aa2-422c-b3f5-a62b20adea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(language: str):\n",
    "    print(f'\\n=== Analysing training split of {language} ===')\n",
    "    df = globals()[language]['train'].to_pandas()\n",
    "    \n",
    "    # Show a sample\n",
    "    display(df.head(3))\n",
    "    \n",
    "    # Count samples\n",
    "    num_samples = len(df)\n",
    "    print(f'There are {num_samples:,} samples.')\n",
    "    \n",
    "    # Get has-answer ratio\n",
    "    frac_has_answer = df.answers.map(lambda dct: dct['text'][0] != '').value_counts(normalize=True).iloc[0]\n",
    "    print(f'{100 * frac_has_answer:.2f}% of the samples have an answer.')\n",
    "    \n",
    "    # Get answer-is-number ratio\n",
    "    num_is_number = len(df.loc[df.answers.map(lambda dct: re.match('[0-9]+', dct['text'][0]) is not None)])\n",
    "    print(f'{100 * num_is_number / num_samples:.2f}% of the answers are numbers.')\n",
    "    \n",
    "    # Get average/median translated context length\n",
    "    avg_translated_context_length = df.context.str.len().mean()\n",
    "    median_translated_context_length = df.context.str.len().median()\n",
    "    print(f'The average translated context has {avg_translated_context_length:,.0f} characters.')\n",
    "    print(f'The median translated context has {median_translated_context_length:,.0f} characters.')\n",
    "    \n",
    "    # Get average original context length\n",
    "    avg_original_context_length = df.context_en.str.len().mean()\n",
    "    median_original_context_length = df.context_en.str.len().median()\n",
    "    print(f'The average original context has {avg_original_context_length:,.0f} characters.')\n",
    "    print(f'The median original context has {median_original_context_length:,.0f} characters.')\n",
    "    \n",
    "    # Get average answer length\n",
    "    avg_answer_length = df.answers.map(lambda dct: len(dct['text'][0])).mean()\n",
    "    median_answer_length = df.answers.map(lambda dct: len(dct['text'][0])).median()\n",
    "    print(f'The mean answer has {avg_answer_length:,.0f} characters.')\n",
    "    print(f'The median answer has {median_answer_length:,.0f} characters.')\n",
    "    \n",
    "    # Plots\n",
    "    plt.hist(df.context.str.len().tolist(), alpha=0.7, density=True, log=True)\n",
    "    plt.title(f'Translated context lengths for {language}', fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4543e-5695-4b60-b40f-bafb25f70b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in ['da', 'sv', 'no']:\n",
    "    analyse(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae29682-7c4d-41e4-b87c-f4c76a51fe94",
   "metadata": {},
   "source": [
    "## Split data across languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e343b-3d8b-4141-a3e4-1a88b89a37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ids(dataset_dict) -> set:\n",
    "    return {id for split in ['train', 'val', 'test'] for id in dataset_dict[split]['example_id']}\n",
    "ids = dict(da=get_all_ids(da), sv=get_all_ids(sv), no=get_all_ids(no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ff6901-f9b7-433f-ab47-781e997b0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_da_ids = np.array(list(ids['da'].difference(ids['sv'].union(ids['no']))))\n",
    "unique_da_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac514d2e-af65-4002-9e69-8bea43d0cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sv_ids = np.array(list(ids['sv'].difference(ids['da'].union(ids['no']))))\n",
    "unique_sv_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5dd50-87d1-4610-a697-42c129a798bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_no_ids = np.array(list(ids['no'].difference(ids['da'].union(ids['sv']))))\n",
    "unique_no_ids.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411c3d3-69bd-48bd-8de3-b9a481be1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_in_common = np.array(list(ids['da'].intersection(ids['sv']).intersection(ids['no'])))\n",
    "ids_in_common.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a6585e-a711-4280-88f2-3d8036690952",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_da = concatenate_datasets([da['train'], da['val'], da['test']]).to_pandas().set_index('example_id')\n",
    "all_da['has_answer'] = all_da.answers.map(lambda dct: dct['text'][0] != \"\")\n",
    "all_da.loc[ids_in_common, 'has_answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a2af7-70b6-4182-9a4c-65c11e020e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sv = concatenate_datasets([sv['train'], sv['val'], sv['test']]).to_pandas().set_index('example_id')\n",
    "all_sv['has_answer'] = all_sv.answers.map(lambda dct: dct['text'][0] != \"\")\n",
    "all_sv.loc[ids_in_common, 'has_answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62bf09-fb7c-4fbe-9c3d-b4c2131a99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_no = concatenate_datasets([no['train'], no['val'], no['test']]).to_pandas().set_index('example_id')\n",
    "all_no['has_answer'] = all_no.answers.map(lambda dct: dct['text'][0] != \"\")\n",
    "all_no.loc[ids_in_common, 'has_answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1a2ad-b2e1-4bf2-a6fa-1c15d9b2754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_test_idxs = train_test_split(ids_in_common, test_size=1000, stratify=all_da.loc[ids_in_common, 'has_answer'])\n",
    "val_idxs, test_idxs = train_test_split(val_test_idxs, test_size=500, stratify=all_da.loc[val_test_idxs, 'has_answer'])\n",
    "val_idxs.size, test_idxs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c99fd-4c2a-47ec-b3eb-6a3c36ab442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_val = all_da.loc[val_idxs]\n",
    "da_test = all_da.loc[test_idxs]\n",
    "da_train_idxs = set(all_da.index.tolist()).difference(val_idxs).difference(test_idxs)\n",
    "da_train = all_da.loc[train_idxs]\n",
    "len(da_train), len(da_val), len(da_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef3fd1-acc4-4d59-9ce7-9a86c3194bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
